{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <pre>\n",
    " ____   ____    _    ____  _____                          _      _     \n",
    "|  _ \\ / ___|  / \\  / ___|| ____|     _ __ ___   ___   __| | ___| |___ \n",
    "| | | | |     / _ \\ \\___ \\|  _| _____| '_ ` _ \\ / _ \\ / _` |/ _ \\ / __|\n",
    "| |_| | |___ / ___ \\ ___) | |__|_____| | | | | | (_) | (_| |  __/ \\__ \\\n",
    "|____/ \\____/_/   \\_\\____/|_____|    |_| |_| |_|\\___/ \\__,_|\\___|_|___/\n",
    "                                                                        \n",
    "</pre>\n",
    "\n",
    "# DCASE-models Notebooks\n",
    "Python Notebooks for [DCASE-models](https://github.com/pzinemanas/DCASE-models)\n",
    "\n",
    "---\n",
    "\n",
    "### About \n",
    "This Notebook reproduces the results for **Sound Event Detection (SED)** presented in:\n",
    "<ul>\n",
    "<li><a href=\"http://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_scaper_waspaa_2017.pdf\"><strong>\n",
    "    Scaper: A Library for Soundscape Synthesis and Augmentation</strong></a>\n",
    "    J. Salamon, D. MacConnell, M. Cartwright, P. Li, and J. P. Bello.\n",
    "    In IEEE Workshop on Applications of Signal Processing to\n",
    "    Audio and Acoustics (WASPAA), New Paltz, NY, USA, Oct. 2017.\n",
    "    <br>\n",
    "   <a type=\"button\" class=\"btn btn-default btn-xs\" target=\"_blank\" href=\"http://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_scaper_waspaa_2017.pdf\"> PDF </a>\n",
    "   <a type=\"button\" class=\"btn btn-default btn-xs\" target=\"_blank\" href=\"https://ieeexplore.ieee.org/document/8170052\"> IEEE</a>\n",
    "    </li>   \n",
    "</ul>\n",
    "\n",
    "### Overview\n",
    "\n",
    "The paper introduces [Scaper](https://github.com/justinsalamon/scaper), an open-source library for soundscape synthesis and augmentation. To illustrate the potential of the library, the authors generate a dataset of 10,000 sound-scapes, namely [URBAN-SED](http://urbansed.weebly.com/), and use it to compare the performance of two state-of-the-art algorithms for sound event detection:\n",
    "- the Convolutional Recurrent Neural Net-work (CRNN) proposed by Cakir et al. [[C-CRNN]](https://ieeexplore.ieee.org/document/7933050)\n",
    "- an adaptation of the Convolutional Neural Network (CNN) proposed by Salamon and Bello [[SB-CNN]](http://ieeexplore.ieee.org/document/7829341/)\n",
    "\n",
    "### Organization\n",
    "\n",
    "The Notebook is organized into the following sections.\n",
    "* [1. Load parameters](#LoadParameters)\n",
    "* [2. Extract features](#ExtractFeatures)\n",
    "* [3. Load data](#LoadData)\n",
    "* [4. Initialize model](#InitModel)\n",
    "* [5. Train model](#TrainModel)\n",
    "* [6. Evaluate model](#EvaluateModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "rootdir_path = '../../'\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import glob\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "sys.path.append(rootdir_path)\n",
    "from dcase_models.util.files import load_json, mkdir_if_not_exists\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.data.datasets import URBAN_SED\n",
    "from dcase_models.data.features import MelSpectrogram\n",
    "from dcase_models.model.models import SB_CNN_SED\n",
    "from dcase_models.data.scaler import Scaler\n",
    "from dcase_models.util.files import load_json\n",
    "from dcase_models.util.data import evaluation_setup\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LoadParameters\"></a>\n",
    "## 1. Load parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset, feature extraction and training parameters are stored in a json file on the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all parameters from json file\n",
    "params = load_json(os.path.join(rootdir_path, 'parameters.json'))\n",
    "# set the dataset we are going to use\n",
    "dataset = 'URBAN_SED'\n",
    "\n",
    "# get dataset parameters\n",
    "params_dataset = params[\"datasets\"][dataset]\n",
    "\n",
    "# get feature extraction parameters\n",
    "params_features = params[\"features\"]\n",
    "\n",
    "# get training parameters\n",
    "params_train = params[\"train\"]\n",
    "# Replacing default training parameters by paper parameters\n",
    "params_train[\"epochs\"]=300\n",
    "params_train[\"early_stopping\"]=100\n",
    "\n",
    "params_model = params[\"models\"][\"SB_CNN_SED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the values of the parameters are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Parameters:\n",
      " {\n",
      "    \"dataset_path\": \"datasets/URBAN-SED_v2.0.0\",\n",
      "    \"evaluation_mode\": \"train-validate-test\"\n",
      "}\n",
      "Features' Parameters:\n",
      " {\n",
      "    \"MelSpectrogram\": {\n",
      "        \"mel_bands\": 64,\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"Openl3\": {\n",
      "        \"content_type\": \"env\",\n",
      "        \"embedding_size\": 512,\n",
      "        \"input_repr\": \"mel256\"\n",
      "    },\n",
      "    \"Spectrogram\": {\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"audio_hop\": 690,\n",
      "    \"audio_win\": 1024,\n",
      "    \"sequence_hop_time\": 1.0,\n",
      "    \"sequence_time\": 2.0,\n",
      "    \"sr\": 22050\n",
      "}\n",
      "Training Parameters:\n",
      " {\n",
      "    \"batch_size\": 32,\n",
      "    \"considered_improvement\": 0,\n",
      "    \"early_stopping\": 100,\n",
      "    \"epochs\": 300,\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"verbose\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print the dataset parameters \n",
    "print(\"Dataset Parameters:\\n\", json.dumps(params_dataset, indent=4, sort_keys=True))\n",
    "# print feature extraction parameters \n",
    "print(\"Features' Parameters:\\n\",json.dumps(params_features, indent=4, sort_keys=True))\n",
    "# print training parameters \n",
    "print(\"Training Parameters:\\n\",json.dumps(params_train, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ExtractFeatures\"></a>\n",
    "## 2. Extract features\n",
    "\n",
    "Initialize Feature Extractor and Data Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Feature Extractor\n",
    "features = MelSpectrogram(sequence_time=params_features['sequence_time'], \n",
    "                          sequence_hop_time=params_features['sequence_hop_time'], \n",
    "                          audio_win=params_features['audio_win'], \n",
    "                          audio_hop=params_features['audio_hop'], \n",
    "                          sr=params_features['sr'],\n",
    "                          **params_features['MelSpectrogram'])\n",
    "\n",
    "print(features.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Data Generator as an instance of URBAN_SED\n",
    "kwargs = {'sequence_hop_time': params_features['sequence_hop_time']}\n",
    "dataset = URBAN_SED(os.path.join(rootdir_path, params_dataset[\"dataset_path\"]), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if dataset exists, and download it if doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features (if they were not extracted before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if not features.check_if_extracted(dataset):\n",
    "    features.extract(dataset)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LoadData\"></a>\n",
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/test folds\n",
    "folds_train, folds_val, folds_test = evaluation_setup('fold1', dataset.fold_list,\\\n",
    "                                             params_dataset['evaluation_mode'],\n",
    "                                             use_validate_set=True)\n",
    "#initialise Data Generator\n",
    "data_gen_train = DataGenerator(dataset, features, folds=folds_train,\\\n",
    "                                batch_size=params_train['batch_size'],\n",
    "                                shuffle=True, train=True, scaler=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also fit a scaler to transform training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting features ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "scaler = Scaler(normalizer=params_model['normalizer'])\n",
    "print('Fitting features ...')\n",
    "scaler.fit(data_gen_train)\n",
    "print('Done!')\n",
    "\n",
    "data_gen_train.set_scaler(scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise validation data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_val = DataGenerator(dataset, features, folds=folds_val,\\\n",
    "                             batch_size=params_train['batch_size'],\n",
    "                             shuffle=False, train=False, scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (64, 64)\n",
      "Y: (10,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X: {data_gen_train.get_data_batch(0)[0][0].shape}\")\n",
    "print(f\"Y: {data_gen_train.get_data_batch(0)[1][0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"InitModel\"></a>\n",
    "## 4. Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                331840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 539,850\n",
      "Trainable params: 539,466\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "X, y = data_gen_train.get_data_batch(0)\n",
    " \n",
    "n_frames_cnn = X.shape[1]\n",
    "n_freq_cnn = X.shape[2]\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "metrics = ['sed']\n",
    "\n",
    "model_container = SB_CNN_SED(model=None, model_path=None, n_classes=n_classes, \n",
    "                             n_frames_cnn=n_frames_cnn, n_freq_cnn=n_freq_cnn,\n",
    "                             metrics=metrics, **params_model['model_arguments'])\n",
    "\n",
    "model_container.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TrainModel\"></a>\n",
    "## 5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "188/188 [==============================] - 299s 2s/step - loss: 3.0765\n",
      "F1 = 0.3037, ER = 4.5373 - Best val F1: 0.3037\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/300\n",
      "188/188 [==============================] - 229s 1s/step - loss: 3.0170\n",
      "F1 = 0.3196, ER = 3.9983 - Best val F1: 0.3196\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 3/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.9718\n",
      "F1 = 0.3201, ER = 3.4725 - Best val F1: 0.3201\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 4/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.9337\n",
      "F1 = 0.3537, ER = 2.9456 - Best val F1: 0.3537\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 5/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.8920\n",
      "F1 = 0.3355, ER = 2.7377 - Best val F1: 0.3537 (3)\n",
      "\n",
      "Epoch 6/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.8469\n",
      "F1 = 0.3870, ER = 1.5939 - Best val F1: 0.3870\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 7/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.8035\n",
      "F1 = 0.3689, ER = 1.6889 - Best val F1: 0.3870 (5)\n",
      "\n",
      "Epoch 8/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.7472\n",
      "F1 = 0.4070, ER = 1.2900 - Best val F1: 0.4070\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 9/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.7073\n",
      "F1 = 0.4694, ER = 0.9778 - Best val F1: 0.4694\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 10/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.6646\n",
      "F1 = 0.3014, ER = 1.6840 - Best val F1: 0.4694 (8)\n",
      "\n",
      "Epoch 11/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.6396\n",
      "F1 = 0.4353, ER = 1.0321 - Best val F1: 0.4694 (8)\n",
      "\n",
      "Epoch 12/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.6120\n",
      "F1 = 0.5127, ER = 0.7532 - Best val F1: 0.5127\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 13/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.5800\n",
      "F1 = 0.4305, ER = 1.1102 - Best val F1: 0.5127 (11)\n",
      "\n",
      "Epoch 14/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.5575\n",
      "F1 = 0.4360, ER = 1.1209 - Best val F1: 0.5127 (11)\n",
      "\n",
      "Epoch 15/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.5312\n",
      "F1 = 0.5184, ER = 0.8152 - Best val F1: 0.5184\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 16/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.5074\n",
      "F1 = 0.5129, ER = 0.7978 - Best val F1: 0.5184 (14)\n",
      "\n",
      "Epoch 17/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.4847\n",
      "F1 = 0.4767, ER = 0.8559 - Best val F1: 0.5184 (14)\n",
      "\n",
      "Epoch 18/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.4665\n",
      "F1 = 0.5338, ER = 0.6204 - Best val F1: 0.5338\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 19/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.4433\n",
      "F1 = 0.4832, ER = 0.8453 - Best val F1: 0.5338 (17)\n",
      "\n",
      "Epoch 20/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.4171\n",
      "F1 = 0.4699, ER = 0.8292 - Best val F1: 0.5338 (17)\n",
      "\n",
      "Epoch 21/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.3971\n",
      "F1 = 0.4667, ER = 0.8151 - Best val F1: 0.5338 (17)\n",
      "\n",
      "Epoch 22/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.3773\n",
      "F1 = 0.4916, ER = 0.8011 - Best val F1: 0.5338 (17)\n",
      "\n",
      "Epoch 23/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.3560\n",
      "F1 = 0.5627, ER = 0.5942 - Best val F1: 0.5627\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 24/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.3447\n",
      "F1 = 0.5275, ER = 0.7040 - Best val F1: 0.5627 (22)\n",
      "\n",
      "Epoch 25/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.3235\n",
      "F1 = 0.5552, ER = 0.5949 - Best val F1: 0.5627 (22)\n",
      "\n",
      "Epoch 26/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.3066\n",
      "F1 = 0.5572, ER = 0.5895 - Best val F1: 0.5627 (22)\n",
      "\n",
      "Epoch 27/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2974\n",
      "F1 = 0.5768, ER = 0.5722 - Best val F1: 0.5768\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 28/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2779\n",
      "F1 = 0.5723, ER = 0.5796 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 29/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2634\n",
      "F1 = 0.4980, ER = 0.7905 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 30/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2517\n",
      "F1 = 0.5644, ER = 0.5929 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 31/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2408\n",
      "F1 = 0.5691, ER = 0.5760 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 32/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2303\n",
      "F1 = 0.5018, ER = 0.7930 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 33/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2215\n",
      "F1 = 0.5309, ER = 0.7424 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 34/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2070\n",
      "F1 = 0.5707, ER = 0.5765 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 35/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.2003\n",
      "F1 = 0.5482, ER = 0.6879 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 36/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.1938\n",
      "F1 = 0.5273, ER = 0.7730 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 37/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.1813\n",
      "F1 = 0.5632, ER = 0.6423 - Best val F1: 0.5768 (26)\n",
      "\n",
      "Epoch 38/300\n",
      "188/188 [==============================] - 215s 1s/step - loss: 2.1732\n",
      "F1 = 0.5772, ER = 0.5763 - Best val F1: 0.5772\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 39/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1600\n",
      "F1 = 0.5111, ER = 0.7717 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 40/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1578\n",
      "F1 = 0.5727, ER = 0.5711 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 41/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1511\n",
      "F1 = 0.5462, ER = 0.6571 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 42/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1368\n",
      "F1 = 0.5581, ER = 0.6476 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 43/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1314\n",
      "F1 = 0.5495, ER = 0.6166 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 44/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1228\n",
      "F1 = 0.5650, ER = 0.6030 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 45/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1210\n",
      "F1 = 0.5077, ER = 0.8167 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 46/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1072\n",
      "F1 = 0.5722, ER = 0.5799 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 47/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.1044\n",
      "F1 = 0.5691, ER = 0.6176 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 48/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0944\n",
      "F1 = 0.5563, ER = 0.6401 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 49/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0960\n",
      "F1 = 0.5221, ER = 0.7886 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 50/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0857\n",
      "F1 = 0.5768, ER = 0.5869 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 51/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0812\n",
      "F1 = 0.5727, ER = 0.5980 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 52/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0743\n",
      "F1 = 0.5678, ER = 0.6125 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 53/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0647\n",
      "F1 = 0.5693, ER = 0.5864 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 54/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0605\n",
      "F1 = 0.5542, ER = 0.6196 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 55/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0526\n",
      "F1 = 0.5590, ER = 0.6642 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 56/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0541\n",
      "F1 = 0.5694, ER = 0.5976 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 57/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 214s 1s/step - loss: 2.0448\n",
      "F1 = 0.5641, ER = 0.6154 - Best val F1: 0.5772 (37)\n",
      "\n",
      "Epoch 58/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0418\n",
      "F1 = 0.5786, ER = 0.5902 - Best val F1: 0.5786\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 59/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0349\n",
      "F1 = 0.5837, ER = 0.5887 - Best val F1: 0.5837\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 60/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0302\n",
      "F1 = 0.5769, ER = 0.5757 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 61/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0195\n",
      "F1 = 0.5283, ER = 0.7306 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 62/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0164\n",
      "F1 = 0.5588, ER = 0.6473 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 63/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0141\n",
      "F1 = 0.5481, ER = 0.7084 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 64/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0124\n",
      "F1 = 0.5572, ER = 0.6458 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 65/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0099\n",
      "F1 = 0.5722, ER = 0.6044 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 66/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0010\n",
      "F1 = 0.5734, ER = 0.5876 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 67/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 2.0000\n",
      "F1 = 0.5743, ER = 0.5898 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 68/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 1.9931\n",
      "F1 = 0.5773, ER = 0.5917 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 69/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 1.9886\n",
      "F1 = 0.5263, ER = 0.7598 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 70/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 1.9822\n",
      "F1 = 0.5755, ER = 0.5950 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 71/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 1.9772\n",
      "F1 = 0.5604, ER = 0.6391 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 72/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 1.9744\n",
      "F1 = 0.5785, ER = 0.5768 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 73/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 1.9745\n",
      "F1 = 0.5687, ER = 0.5849 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 74/300\n",
      "188/188 [==============================] - 214s 1s/step - loss: 1.9725\n",
      "F1 = 0.5810, ER = 0.5912 - Best val F1: 0.5837 (58)\n",
      "\n",
      "Epoch 75/300\n",
      " 21/188 [==>...........................] - ETA: 3:10 - loss: 1.9212"
     ]
    }
   ],
   "source": [
    "#define path to save weights and training log\n",
    "mkdir_if_not_exists('./output')\n",
    "exp_folder = './output/SB_CNN'\n",
    "mkdir_if_not_exists(exp_folder)\n",
    "\n",
    "\n",
    "kwargs = {'label_list': dataset.label_list}\n",
    "\n",
    "# Uncomment the following line to running fewer epochs \n",
    "#params_train[\"epochs\"]= 50\n",
    "\n",
    "model_container.train(data_gen_train, data_gen_val, weights_path=exp_folder, **params_train, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EvaluateModel\"></a>\n",
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best_weights\n",
    "model_container.load_model_weights(exp_folder)\n",
    "data_gen_test = DataGenerator(dataset, features, folds=folds_test,\n",
    "                              batch_size=params_train['batch_size'],\n",
    "                              shuffle=False, train=False, scaler=scaler)\n",
    "\n",
    "kwargs = {'sequence_time_sec': params_features['sequence_hop_time'],\n",
    "          'metric_resolution_sec': 1.0}\n",
    "results = model_container.evaluate(data_gen_test, label_list=dataset.label_list, **kwargs)\n",
    "\n",
    "print(results[metrics[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
