{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <pre>\n",
    " ____   ____    _    ____  _____                          _      _     \n",
    "|  _ \\ / ___|  / \\  / ___|| ____|     _ __ ___   ___   __| | ___| |___ \n",
    "| | | | |     / _ \\ \\___ \\|  _| _____| '_ ` _ \\ / _ \\ / _` |/ _ \\ / __|\n",
    "| |_| | |___ / ___ \\ ___) | |__|_____| | | | | | (_) | (_| |  __/ \\__ \\\n",
    "|____/ \\____/_/   \\_\\____/|_____|    |_| |_| |_|\\___/ \\__,_|\\___|_|___/\n",
    "                                                                        \n",
    "</pre>\n",
    "\n",
    "# DCASE-models Notebooks\n",
    "Python Notebooks for [DCASE-models](https://github.com/pzinemanas/DCASE-models)\n",
    "\n",
    "---\n",
    "\n",
    "### About \n",
    "This Notebook reproduces the results for **Sound Event Detection (SED)** presented in:\n",
    "<ul>\n",
    "<li><a href=\"http://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_scaper_waspaa_2017.pdf\"><strong>\n",
    "    Scaper: A Library for Soundscape Synthesis and Augmentation</strong></a>\n",
    "    J. Salamon, D. MacConnell, M. Cartwright, P. Li, and J. P. Bello.\n",
    "    In IEEE Workshop on Applications of Signal Processing to\n",
    "    Audio and Acoustics (WASPAA), New Paltz, NY, USA, Oct. 2017.\n",
    "    <br>\n",
    "   <a type=\"button\" class=\"btn btn-default btn-xs\" target=\"_blank\" href=\"http://www.justinsalamon.com/uploads/4/3/9/4/4394963/salamon_scaper_waspaa_2017.pdf\"> PDF </a>\n",
    "   <a type=\"button\" class=\"btn btn-default btn-xs\" target=\"_blank\" href=\"https://ieeexplore.ieee.org/document/8170052\"> IEEE</a>\n",
    "    </li>   \n",
    "</ul>\n",
    "\n",
    "### Overview\n",
    "\n",
    "The paper introduces [Scaper](https://github.com/justinsalamon/scaper), an open-source library for soundscape synthesis and augmentation. To illustrate the potential of the library, the authors generate a dataset of 10,000 sound-scapes, namely [URBAN-SED](http://urbansed.weebly.com/), and use it to compare the performance of two state-of-the-art algorithms for sound event detection:\n",
    "- the Convolutional Recurrent Neural Net-work (CRNN) proposed by Cakir et al. [[C-CRNN]](https://ieeexplore.ieee.org/document/7933050)\n",
    "- an adaptation of the Convolutional Neural Network (CNN) proposed by Salamon and Bello [[SB-CNN]](http://ieeexplore.ieee.org/document/7829341/)\n",
    "\n",
    "### Organization\n",
    "\n",
    "The Notebook is organized into the following sections.\n",
    "* [1. Load parameters](#LoadParameters)\n",
    "* [2. Init data generator and extract features](#ExtractFeatures)\n",
    "* [3. Load data](#LoadData)\n",
    "* [4. Initialize model](#InitModel)\n",
    "* [5. Train model](#TrainModel)\n",
    "* [6. Evaluate model](#EvaluateModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "rootdir_path = '../../'\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import glob\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "sys.path.append(rootdir_path)\n",
    "from dcase_models.utils.files import load_json, mkdir_if_not_exists\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.data.datasets import URBAN_SED\n",
    "from dcase_models.data.features import MelSpectrogram\n",
    "from dcase_models.model.models import SB_CNN_SED\n",
    "from dcase_models.data.scaler import Scaler\n",
    "from dcase_models.utils.files import load_json\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LoadeParameters\"></a>\n",
    "## 1. Load parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset, feature extraction and training parameters are stored in a json file on the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all parameters from json file\n",
    "params = load_json(os.path.join(rootdir_path, 'parameters.json'))\n",
    "# set the dataset we are going to use\n",
    "dataset = 'URBAN_SED'\n",
    "\n",
    "# get dataset parameters\n",
    "params_dataset = params[\"datasets\"][dataset]\n",
    "\n",
    "# get feature extraction parameters\n",
    "params_features = params[\"features\"]\n",
    "\n",
    "# get training parameters\n",
    "params_train = params[\"train\"]\n",
    "\n",
    "params_model = params[\"models\"][\"SB_CNN_SED\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the values of the parameters are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Parameters:\n",
      " {\n",
      "    \"dataset_path\": \"datasets/URBAN-SED_v2.0.0\",\n",
      "    \"evaluation_mode\": \"train-validate-test\"\n",
      "}\n",
      "Features' Parameters:\n",
      " {\n",
      "    \"MelSpectrogram\": {\n",
      "        \"mel_bands\": 64,\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"Openl3\": {\n",
      "        \"content_type\": \"env\",\n",
      "        \"embedding_size\": 512,\n",
      "        \"input_repr\": \"mel256\"\n",
      "    },\n",
      "    \"Spectrogram\": {\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"audio_hop\": 690,\n",
      "    \"audio_win\": 1024,\n",
      "    \"sequence_hop_time\": 1.0,\n",
      "    \"sequence_time\": 2.0,\n",
      "    \"sr\": 22050\n",
      "}\n",
      "Training Parameters:\n",
      " {\n",
      "    \"batch_size\": 256,\n",
      "    \"considered_improvement\": 0,\n",
      "    \"early_stopping\": 30,\n",
      "    \"epochs\": 50,\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"verbose\": 1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# print the dataset parameters \n",
    "print(\"Dataset Parameters:\\n\", json.dumps(params_dataset, indent=4, sort_keys=True))\n",
    "# print feature extraction parameters \n",
    "print(\"Features' Parameters:\\n\",json.dumps(params_features, indent=4, sort_keys=True))\n",
    "# print training parameters \n",
    "print(\"Training Parameters:\\n\",json.dumps(params_train, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ExtractFeatures\"></a>\n",
    "## 2. Initialize Data Generator and Extract features\n",
    "\n",
    "Initialize Feature Extractor and Data Generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "# Initialize Feature Extractor\n",
    "feature_extractor = MelSpectrogram(sequence_time=params_features['sequence_time'], \\\n",
    "                                   sequence_hop_time=params_features['sequence_hop_time'], \n",
    "                                   audio_win=params_features['audio_win'], \n",
    "                                   audio_hop=params_features['audio_hop'], \n",
    "                                   sr=params_features['sr'],\n",
    "                                   **params_features['MelSpectrogram'])\n",
    "\n",
    "print(feature_extractor.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Data Generator as an instance of URBAN_SED\n",
    "kwargs = {'sequence_hop_time': params_features['sequence_hop_time']}\n",
    "dataset = URBAN_SED(os.path.join(rootdir_path, params_dataset[\"dataset_path\"]), **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if dataset exists, and download it if doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(dataset, feature_extractor,\n",
    "                               evaluation_mode='train-validate-test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the features (if they were not extracted before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "if not data_generator.check_if_features_extracted():\n",
    "    data_generator.extract_features()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"LoadData\"></a>\n",
    "## 3. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "fold: [############################################################] 3/3\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Loading data... ')\n",
    "data_generator.load_data()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also fit a scaler and transform the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_test = 'test'\n",
    "\n",
    "X_train, Y_train, X_val, Y_val = data_generator.get_data_for_training(fold_test)\n",
    "scaler = Scaler(normalizer=params_model['normalizer'])\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 64, 64) (60000, 10) (10, 64, 64) (10, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_val[0].shape, Y_val[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"InitModel\"></a>\n",
    "## 4. Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 60, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 9, 9, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                331840    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 539,850\n",
      "Trainable params: 539,466\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_frames_cnn = X_train.shape[1]\n",
    "n_freq_cnn = X_train.shape[2]\n",
    "n_classes = Y_train.shape[1]\n",
    "\n",
    "metrics = ['sed']\n",
    "\n",
    "model_container = SB_CNN_SED(model=None, model_path=None, n_classes=n_classes, \n",
    "                             n_frames_cnn=n_frames_cnn, n_freq_cnn=n_freq_cnn,\n",
    "                             metrics=metrics, **params_model['model_arguments'])\n",
    "\n",
    "model_container.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TrainModel\"></a>\n",
    "## 5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 3.0547\n",
      "F1 = 0.2905, ER = 4.6313 - Best val F1: 0.2905\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 2.9795\n",
      "F1 = 0.3431, ER = 3.2604 - Best val F1: 0.3431\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 2.9345\n",
      "F1 = 0.3299, ER = 2.8007 - Best val F1: 0.3431 (1)\n",
      "\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 2.8806\n",
      "F1 = 0.3621, ER = 2.1262 - Best val F1: 0.3621\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 5/50\n",
      "49408/60000 [=======================>......] - ETA: 1s - loss: 2.8207"
     ]
    }
   ],
   "source": [
    "exp_folder = './'\n",
    "\n",
    "kwargs = {'label_list': dataset.label_list}\n",
    "model_container.train(X_train, Y_train, X_val, Y_val, weights_path=exp_folder, **params_train, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"EvaluateModel\"></a>\n",
    "## 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.99676514 0.9901514\n",
      "Segment based metrics\n",
      "========================================\n",
      "  Evaluated length                  : 20000.00 sec\n",
      "  Evaluated files                   : 2000 \n",
      "  Segment length                    : 1.00 sec\n",
      "\n",
      "  Overall metrics (micro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 14.68 %\n",
      "    Precision                       : 7.92 %\n",
      "    Recall                          : 99.91 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 11.61 \n",
      "    Substitution rate               : 0.00 \n",
      "    Deletion rate                   : 0.00 \n",
      "    Insertion rate                  : 11.61 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 99.91 %\n",
      "    Specificity                     : 0.05 %\n",
      "    Balanced accuracy               : 49.98 %\n",
      "    Accuracy                        : 7.96 %\n",
      "\n",
      "  Class-wise average metrics (macro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 14.68 %\n",
      "    Precision                       : 7.92 %\n",
      "    Recall                          : 99.89 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 11.68 \n",
      "    Deletion rate                   : 0.00 \n",
      "    Insertion rate                  : 11.68 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 99.89 %\n",
      "    Specificity                     : 0.05 %\n",
      "    Balanced accuracy               : 49.97 %\n",
      "    Accuracy                        : 7.96 %\n",
      "  \n",
      "\n",
      "  Class-wise metrics\n",
      "  ======================================\n",
      "    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n",
      "    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n",
      "    air_condit.. | 1701    20000 | 15.7%    8.5%     100.0% | 10.76    0.00     10.76  | 100.0%   0.0%     50.0%    8.5%    \n",
      "    car_horn     | 1343    19951 | 12.5%    6.7%     99.4%  | 13.87    0.01     13.86  | 99.4%    0.2%     49.8%    6.9%    \n",
      "    children_p.. | 1708    20000 | 15.7%    8.5%     100.0% | 10.71    0.00     10.71  | 100.0%   0.0%     50.0%    8.5%    \n",
      "    dog_bark     | 1524    20000 | 14.2%    7.6%     100.0% | 12.12    0.00     12.12  | 100.0%   0.0%     50.0%    7.6%    \n",
      "    drilling     | 1728    20000 | 15.9%    8.6%     100.0% | 10.57    0.00     10.57  | 100.0%   0.0%     50.0%    8.6%    \n",
      "    engine_idl.. | 1574    20000 | 14.6%    7.9%     100.0% | 11.71    0.00     11.71  | 100.0%   0.0%     50.0%    7.9%    \n",
      "    gun_shot     | 1467    19944 | 13.6%    7.3%     99.5%  | 12.60    0.00     12.60  | 99.5%    0.3%     49.9%    7.5%    \n",
      "    jackhammer   | 1568    20000 | 14.5%    7.8%     100.0% | 11.76    0.00     11.76  | 100.0%   0.0%     50.0%    7.8%    \n",
      "    siren        | 1638    20000 | 15.1%    8.2%     100.0% | 11.21    0.00     11.21  | 100.0%   0.0%     50.0%    8.2%    \n",
      "    street_music | 1601    20000 | 14.8%    8.0%     100.0% | 11.49    0.00     11.49  | 100.0%   0.0%     50.0%    8.0%    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best_weights\n",
    "model_container.load_model_weights(exp_folder)\n",
    "# Test model\n",
    "X_test, Y_test = data_generator.get_data_for_testing(fold_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "print(np.amin(X_test), np.amax(X_test))\n",
    "kwargs = {'sequence_time_sec': params_features['sequence_hop_time'],\n",
    "          'metric_resolution_sec': 1.0,\n",
    "          'label_list': dataset.label_list}\n",
    "results = model_container.evaluate(X_test, Y_test, **kwargs)\n",
    "\n",
    "print(results['sed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
