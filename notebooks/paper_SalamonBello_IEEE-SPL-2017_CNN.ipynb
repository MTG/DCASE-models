{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SB_CNN Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "sys.path.append('../')\n",
    "from dcase_models.utils.files import load_json, mkdir_if_not_exists\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.data.datasets import UrbanSound8k\n",
    "from dcase_models.data.datasets import ESC10\n",
    "from dcase_models.data.features import MelSpectrogram\n",
    "from dcase_models.model.models import SB_CNN\n",
    "from dcase_models.data.scaler import Scaler\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features parameters\n",
    "sequence_time = 2.0\n",
    "sequence_hop_time = 0.5\n",
    "audio_hop = 670\n",
    "audio_win = 1024\n",
    "n_fft = 1024\n",
    "sr = 22050\n",
    "mel_bands = 128\n",
    "\n",
    "# normalizer\n",
    "normalizer = 'minmax'\n",
    "\n",
    "# train parameters\n",
    "early_stopping = 10\n",
    "epochs = 5\n",
    "considered_improvement = 0\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "verbose = 1\n",
    "optimizer = 'Adam'\n",
    "\n",
    "# dataset parameters\n",
    "#dataset_path = '../../../../data/pzinemanas/UrbanSound8K'\n",
    "dataset_path = '../../../../data/pzinemanas/ESC50'\n",
    "audio_folder = 'audio22050'\n",
    "feature_folder = 'features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Feature Extractor and Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_list ['dog', 'rooster', 'rain', 'sea_waves', 'crackling_fire', 'crying_baby', 'sneezing', 'clock_tick', 'helicopter', 'chainsaw']\n"
     ]
    }
   ],
   "source": [
    "# Init Feature Extractor\n",
    "feature_extractor = MelSpectrogram(sequence_time=sequence_time, \n",
    "                                   sequence_hop_time=sequence_hop_time, \n",
    "                                   audio_win=audio_win, \n",
    "                                   audio_hop=audio_hop, \n",
    "                                   n_fft=n_fft, \n",
    "                                   sr=sr, mel_bands=mel_bands)\n",
    "\n",
    "# Init Data Generator\n",
    "dataset = ESC10(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = DataGenerator(dataset, feature_extractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_generator.extract_features()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "fold: [############################################################] 5/5\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Loading data... ')\n",
    "data_generator.load_data()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_test = 'fold1'\n",
    "\n",
    "X_train, Y_train, X_val, Y_val = data_generator.get_data_for_training(fold_test)\n",
    "scaler = Scaler(normalizer=normalizer)\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 128 10\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 64, 128, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 60, 124, 24)       624       \n",
      "_________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)      (None, 30, 62, 24)        0         \n",
      "_________________________________________________________________\n",
      "batchnorm1 (BatchNormalizati (None, 30, 62, 24)        96        \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 26, 58, 48)        28848     \n",
      "_________________________________________________________________\n",
      "maxpool2 (MaxPooling2D)      (None, 6, 29, 48)         0         \n",
      "_________________________________________________________________\n",
      "batchnorm2 (BatchNormalizati (None, 6, 29, 48)         192       \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 2, 25, 48)         57648     \n",
      "_________________________________________________________________\n",
      "batchnorm3 (BatchNormalizati (None, 2, 25, 48)         192       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 2400)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 64)                153664    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 241,914\n",
      "Trainable params: 241,674\n",
      "Non-trainable params: 240\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_frames_cnn = X_train.shape[1]\n",
    "n_freq_cnn = X_train.shape[2]\n",
    "n_classes = Y_train.shape[1]\n",
    "print(n_frames_cnn, n_freq_cnn, n_classes)\n",
    "\n",
    "model_container = SB_CNN(model=None, model_path=None, n_classes=n_classes, \n",
    "                         n_frames_cnn=n_frames_cnn, n_freq_cnn=n_freq_cnn)\n",
    "\n",
    "model_container.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2640/2640 [==============================] - 1s 366us/step - loss: 2.3939\n",
      "Acc = 0.6125 - Best val Acc: 0.6125 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/5\n",
      "2640/2640 [==============================] - 0s 160us/step - loss: 1.4687\n",
      "Acc = 0.6125 - Best val Acc: 0.6125 (0)\n",
      "\n",
      "Epoch 3/5\n",
      "2640/2640 [==============================] - 0s 181us/step - loss: 1.1995\n",
      "Acc = 0.8625 - Best val Acc: 0.8625 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 4/5\n",
      "2640/2640 [==============================] - 0s 172us/step - loss: 0.9689\n",
      "Acc = 0.7875 - Best val Acc: 0.8625 (2)\n",
      "\n",
      "Epoch 5/5\n",
      "2640/2640 [==============================] - 0s 179us/step - loss: 0.8988\n",
      "Acc = 0.7875 - Best val Acc: 0.8625 (2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_folder = './'\n",
    "\n",
    "train_arguments = {'early_stopping': early_stopping,\n",
    "                  'epochs': epochs,\n",
    "                  'considered_improvement': considered_improvement,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'batch_size': batch_size,\n",
    "                  'verbose': verbose,\n",
    "                  'optimizer': optimizer}\n",
    "\n",
    "model_container.train(X_train, Y_train, X_val, Y_val, weights_path=exp_folder, **train_arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# Load best_weights\n",
    "model_container.load_model_weights(exp_folder)\n",
    "\n",
    "# Test model\n",
    "X_test, Y_test = data_generator.get_data_for_testing(fold_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "results = model_container.evaluate(X_test, Y_test)\n",
    "\n",
    "print(results['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
