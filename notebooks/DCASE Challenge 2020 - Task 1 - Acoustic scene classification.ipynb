{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DCASE Challenge 2020 - Task 1 - Acoustic scene classification\n",
    "\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features parameters\n",
    "sequence_time = 2.0\n",
    "sequence_hop_time = 2.0\n",
    "audio_hop = 1024\n",
    "audio_win = 2048\n",
    "n_fft = 2048\n",
    "sr = 44100\n",
    "features_name = 'MelSpectrogram'\n",
    "features_kwargs = {'mel_bands': 40}\n",
    "#features_name = 'Openl3'\n",
    "#features_kwargs = {'content_type': 'music', \n",
    "#                   'input_repr': 'mel256',\n",
    "#                   'embedding_size': 512} \n",
    "\n",
    "# normalizer\n",
    "normalizer = 'minmax'\n",
    "\n",
    "# train parameters\n",
    "early_stopping = 10\n",
    "epochs = 20\n",
    "considered_improvement = 0\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "verbose = 1\n",
    "optimizer = 'Adam'\n",
    "\n",
    "# dataset parameters\n",
    "dataset_name = 'TAUUrbanAcousticScenes2020Mobile'\n",
    "dataset_path = '../../../../data/pzinemanas/TAUUrbanAcousticScenes2020Mobile'\n",
    "audio_folder = 'audio'\n",
    "feature_folder = 'features' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "sys.path.append('../')\n",
    "from dcase_models.utils.files import load_json, mkdir_if_not_exists\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.model.container import DCASEModelContainer\n",
    "from dcase_models.data.datasets import get_available_datasets\n",
    "from dcase_models.data.features import get_available_features\n",
    "from dcase_models.model.models import get_available_models\n",
    "from dcase_models.data.scaler import Scaler\n",
    "from dcase_models.data.feature_extractor import FeatureExtractor\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autopool import AutoPool1D\n",
    "from keras.layers import Input, TimeDistributed, Dense\n",
    "from keras.models import Model\n",
    "class DCASE2020Task1Baseline(DCASEModelContainer):\n",
    "    def __init__(self, model=None, folder=None, metrics=['accuracy'], n_frames_cnn=96, \n",
    "                n_freq_cnn=64, n_classes=10, hidden_layers_size=[512, 128]):\n",
    "\n",
    "        if folder is None:\n",
    "            # input\n",
    "            inputs = Input(shape=(n_frames_cnn,n_freq_cnn), dtype='float32', name='input')\n",
    "\n",
    "            num_hidden_layers = len(hidden_layers_size)\n",
    "            # Hidden layers\n",
    "            for idx in range(num_hidden_layers):\n",
    "                if idx == 0:\n",
    "                    y = inputs\n",
    "                y = TimeDistributed(Dense(hidden_layers_size[idx], activation='relu',\n",
    "                                    name='dense_{}'.format(idx+1)))(y)\n",
    "\n",
    "            # Output layer\n",
    "            y = TimeDistributed(Dense(n_classes, activation='softmax',\n",
    "                                name='output_t'))(y)\n",
    "\n",
    "            # Apply autopool over time dimension\n",
    "            y = AutoPool1D(axis=1, name='output')(y)\n",
    "\n",
    "            # Create model\n",
    "            model = Model(inputs=inputs, outputs=y, name='model')\n",
    "\n",
    "        super().__init__(model=model, folder=folder, model_name='DCASE2020Task5Baseline', metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define feature extractor and data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature extractor class\n",
    "feature_extractor_class = get_available_features()[features_name]\n",
    "# init feature extractor\n",
    "feature_extractor = feature_extractor_class(sequence_time=sequence_time, \n",
    "                                            sequence_hop_time=sequence_hop_time, \n",
    "                                            audio_win=audio_win, \n",
    "                                            audio_hop=audio_hop, \n",
    "                                            n_fft=n_fft, \n",
    "                                            sr=sr, **features_kwargs)\n",
    "\n",
    "# get dataset class\n",
    "data_generator_class = get_available_datasets()[dataset_name]\n",
    "# init data_generator\n",
    "data_generator = data_generator_class(dataset_path, feature_folder, features_name, \n",
    "                                      audio_folder=audio_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract features if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from folder:  ../../../../data/pzinemanas/TAUUrbanAcousticScenes2020Mobile/audio\n",
      "../../../../data/pzinemanas/TAUUrbanAcousticScenes2020Mobile/features/MelSpectrogram/parameters.json\n",
      "Features already were calculated, continue...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "folders_list = data_generator.get_folder_lists()\n",
    "for audio_features_paths in folders_list:\n",
    "    print('Extracting features from folder: ', audio_features_paths['audio'])\n",
    "    response = feature_extractor.extract(audio_features_paths['audio'], audio_features_paths['features'])\n",
    "    if response is None:\n",
    "        print('Features already were calculated, continue...')\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... \n",
      "fold: [############################################################] 2/2\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "print('Loading data... ')\n",
    "data_generator.load_data()\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data for trainint and apply scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_val, Y_val = data_generator.get_data_for_training()\n",
    "scaler = Scaler(normalizer=normalizer)\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 40 10\n",
      "WARNING:tensorflow:From /data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 84, 40)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 84, 512)           20992     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 84, 128)           65664     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 84, 10)            1290      \n",
      "_________________________________________________________________\n",
      "output (AutoPool1D)          (None, 10)                10        \n",
      "=================================================================\n",
      "Total params: 87,956\n",
      "Trainable params: 87,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_frames_cnn = X_train.shape[1]\n",
    "n_freq_cnn = X_train.shape[2]\n",
    "n_classes = Y_train.shape[1]\n",
    "print(n_frames_cnn, n_freq_cnn, n_classes)\n",
    "model_container = DCASE2020Task1Baseline(model=None, folder=None, n_classes=n_classes, \n",
    "                                         n_frames_cnn=n_frames_cnn, n_freq_cnn=n_freq_cnn)\n",
    "\n",
    "model_container.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set paths and save model json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model to DCASE2020Task1Baseline/TAUUrbanAcousticScenes2020Mobile\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DCASE2020Task1Baseline'\n",
    "mkdir_if_not_exists(model_name)\n",
    "exp_folder = os.path.join(model_name, dataset_name)\n",
    "mkdir_if_not_exists(exp_folder)\n",
    "\n",
    "# save model as json\n",
    "print('saving model to %s' % exp_folder)\n",
    "model_container.save_model_json(exp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /data/pzinemanas/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/20\n",
      "83772/83772 [==============================] - 5s 58us/step - loss: 1.5930\n",
      "Acc = 0.4986 -  Best val Acc: 0.4986 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/20\n",
      "83772/83772 [==============================] - 3s 35us/step - loss: 1.3795\n",
      "Acc = 0.5445 -  Best val Acc: 0.5445 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 3/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.3000\n",
      "Acc = 0.5764 -  Best val Acc: 0.5764 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 4/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.2440\n",
      "Acc = 0.6151 -  Best val Acc: 0.6151 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 5/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.2011\n",
      "Acc = 0.6230 -  Best val Acc: 0.6230 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 6/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.1602\n",
      "Acc = 0.6325 -  Best val Acc: 0.6325 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 7/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.1224\n",
      "Acc = 0.6569 -  Best val Acc: 0.6569 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 8/20\n",
      "83772/83772 [==============================] - 3s 35us/step - loss: 1.0947\n",
      "Acc = 0.6725 -  Best val Acc: 0.6725 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 9/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.0666\n",
      "Acc = 0.6733 -  Best val Acc: 0.6733 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 10/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.0384\n",
      "Acc = 0.7007 -  Best val Acc: 0.7007 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 11/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 1.0205\n",
      "Acc = 0.7089 -  Best val Acc: 0.7089 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 12/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 0.9949\n",
      "Acc = 0.7028 - Best val Acc: 0.7089 (10)\n",
      "\n",
      "Epoch 13/20\n",
      "83772/83772 [==============================] - 3s 35us/step - loss: 0.9738\n",
      "Acc = 0.7184 -  Best val Acc: 0.7184 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 14/20\n",
      "83772/83772 [==============================] - 3s 35us/step - loss: 0.9585\n",
      "Acc = 0.7460 -  Best val Acc: 0.7460 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 15/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 0.9397\n",
      "Acc = 0.7283 - Best val Acc: 0.7460 (13)\n",
      "\n",
      "Epoch 16/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 0.9258\n",
      "Acc = 0.7451 - Best val Acc: 0.7460 (13)\n",
      "\n",
      "Epoch 17/20\n",
      "83772/83772 [==============================] - 3s 34us/step - loss: 0.9094\n",
      "Acc = 0.7583 -  Best val Acc: 0.7583 (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 18/20\n",
      "83772/83772 [==============================] - 3s 35us/step - loss: 0.8976\n",
      "Acc = 0.7332 - Best val Acc: 0.7583 (16)\n",
      "\n",
      "Epoch 19/20\n",
      "83772/83772 [==============================] - 3s 35us/step - loss: 0.8793\n",
      "Acc = 0.7514 - Best val Acc: 0.7583 (16)\n",
      "\n",
      "Epoch 20/20\n",
      "83772/83772 [==============================] - 3s 35us/step - loss: 0.8684\n",
      "Acc = 0.7686 -  Best val Acc: 0.7686 (IMPROVEMENT, saving)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_arguments = {'early_stopping': early_stopping,\n",
    "                  'epochs': epochs,\n",
    "                  'considered_improvement': considered_improvement,\n",
    "                  'learning_rate': learning_rate,\n",
    "                  'batch_size': batch_size,\n",
    "                  'verbose': verbose,\n",
    "                  'optimizer': optimizer}\n",
    "\n",
    "model_container.train(X_train, Y_train, X_val, Y_val, weights_path=exp_folder, **train_arguments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1997978436657682\n"
     ]
    }
   ],
   "source": [
    "# load best_weights\n",
    "model_container.load_model_weights(exp_folder)\n",
    "\n",
    "# test model\n",
    "X_test, Y_test = data_generator.get_data_for_testing()\n",
    "X_test = scaler.transform(X_test)\n",
    "results = model_container.evaluate(X_test, Y_test)\n",
    "\n",
    "print(results['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('tf_gpu': conda)",
   "language": "python",
   "name": "python37664bittfgpuconda4ce1188e0ad54433a74851c49d21ab14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
