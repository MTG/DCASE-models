{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    " ____   ____    _    ____  _____                          _      _     \n",
    "|  _ \\ / ___|  / \\  / ___|| ____|     _ __ ___   ___   __| | ___| |___ \n",
    "| | | | |     / _ \\ \\___ \\|  _| _____| '_ ` _ \\ / _ \\ / _` |/ _ \\ / __|\n",
    "| |_| | |___ / ___ \\ ___) | |__|_____| | | | | | (_) | (_| |  __/ \\__ \\\n",
    "|____/ \\____/_/   \\_\\____/|_____|    |_| |_| |_|\\___/ \\__,_|\\___|_|___/\n",
    "                                                                        \n",
    "</pre>\n",
    "\n",
    "# DCASE-models Notebooks\n",
    "Python Notebooks for [DCASE-models](https://github.com/pzinemanas/DCASE-models)\n",
    "\n",
    "---\n",
    "### About\n",
    "\n",
    "This notebook shows how to train a model using [DCASE-models](https://github.com/pzinemanas/DCASE-models).\n",
    "\n",
    "### Overview\n",
    "\n",
    "The dataset used is [Urban SED](http://urbansed.weebly.com/), an adaptation of the Convolutional Neural Network (CNN) proposed by Salamon and Bello [[SB-CNN]](http://ieeexplore.ieee.org/document/7829341/) is trained end evaluated.\n",
    "\n",
    "For details on how to download a dataset, extract features or perform data augmentation refer to the respective notebooks.\n",
    "\n",
    "\n",
    "### Organization\n",
    "\n",
    "The Notebook is organized into the following sections.\n",
    "* [1. Prepare data](#Data)\n",
    "* [2. Initialize model](#InitModel)\n",
    "* [3. Train model](#TrainModel)\n",
    "* [4. Evaluate model](#Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "rootdir_path = '../../'\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "sys.path.append(rootdir_path)\n",
    "\n",
    "from dcase_models.data.datasets import URBAN_SED\n",
    "from dcase_models.data.features import MelSpectrogram\n",
    "from dcase_models.model.models import SB_CNN_SED\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.data.data_augmentation import AugmentedDataset\n",
    "from dcase_models.data.scaler import Scaler\n",
    "from dcase_models.util.files import load_json\n",
    "from dcase_models.util.files import mkdir_if_not_exists, save_pickle\n",
    "from dcase_models.util.data import evaluation_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Data\"></a>\n",
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the following steps could be  ommited if *feature_extraction* and *download_and_prepare_datasets* have already been run. Nonetheless, they have been included to make the notebook self contained. For a more detailed explanation refer to the corresponding notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load parameters from json file\n",
    "parameters_file = os.path.join(rootdir_path, 'parameters.json')\n",
    "params = load_json(parameters_file)\n",
    "params_dataset = params['datasets']['URBAN_SED']\n",
    "params_features = params['features']\n",
    "params_train = params['train']\n",
    "params_model = params['models']['SB_CNN_SED']\n",
    "\n",
    "#print dataset parmeters\n",
    "print(json.dumps(params_dataset, indent=4, sort_keys=True))\n",
    "# print feature extraction parameters \n",
    "print(json.dumps(params_model, indent=4, sort_keys=True))\n",
    "# print training parameters \n",
    "print(json.dumps(params_train, indent=4, sort_keys=True))\n",
    "\n",
    "features =  MelSpectrogram(\n",
    "    sequence_time=params_features['sequence_time'],\n",
    "    sequence_hop_time=params_features['sequence_hop_time'], \n",
    "    audio_win=params_features['audio_win'], \n",
    "    audio_hop=params_features['audio_hop'],  \n",
    "    sr=params_features['sr'], \n",
    "    **params_features['MelSpectrogram']\n",
    ")\n",
    "\n",
    "dataset_path = os.path.join(rootdir_path, params_dataset[\"dataset_path\"])\n",
    "dataset = URBAN_SED(dataset_path)\n",
    "\n",
    "if dataset.check_if_downloaded():\n",
    "    print('URBAN_SED dataset was already downloaded. ')\n",
    "else:\n",
    "    print('downloading URBAN_SED dataset')\n",
    "    dataset.download()\n",
    "# Extract features\n",
    "if features.check_if_extracted(dataset):\n",
    "    print('Features were already extracted for URBAN_SED dataset. ')\n",
    "else:\n",
    "    print('Extracting features ...')\n",
    "    features.extract(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise data generators and fit scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train/test folds\n",
    "folds_train, folds_val, folds_test = evaluation_setup(\n",
    "    'test', dataset.fold_list, params_dataset['evaluation_mode'], use_validate_set=True\n",
    ")\n",
    "\n",
    "#initialise train Data Generator\n",
    "data_gen_train = DataGenerator(\n",
    "    dataset, features, folds=folds_train, batch_size=params_train['batch_size'],\n",
    "    shuffle=True, train=True, scaler=None\n",
    ")\n",
    "\n",
    "# fit scaler\n",
    "scaler = Scaler(normalizer=params_model['normalizer'])\n",
    "print('Fitting scaler ...')\n",
    "scaler.fit(data_gen_train)\n",
    "print('Done!')\n",
    "\n",
    "data_gen_train.set_scaler(scaler)\n",
    "\n",
    "#Initialise validation data Generator\n",
    "data_gen_val = DataGenerator(\n",
    "    dataset, features, folds=folds_val, batch_size=params_train['batch_size'],\n",
    "    shuffle=False, train=False, scaler=scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Model\"></a>\n",
    "## 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_shape = features.get_shape()\n",
    "n_frames_cnn = features_shape[1]\n",
    "n_freq_cnn = features_shape[2]\n",
    "n_classes = len(dataset.label_list)\n",
    "\n",
    "metrics = ['sed']\n",
    "\n",
    "model_container = SB_CNN_SED(\n",
    "    model=None, model_path=None, n_classes=n_classes, \n",
    "    n_frames_cnn=n_frames_cnn, n_freq_cnn=n_freq_cnn,\n",
    "    metrics=metrics, **params_model['model_arguments']\n",
    ")\n",
    "\n",
    "model_container.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Train\"></a>\n",
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_folder='./output/basics'\n",
    "if not os.path.exists(exp_folder):\n",
    "    os.makedirs(exp_folder)\n",
    "\n",
    "model_container.train(\n",
    "    data_gen_train, data_gen_val,\n",
    "    label_list=dataset.label_list,\n",
    "    weights_path=exp_folder,\n",
    "    sequence_time_sec=params_features['sequence_hop_time'],\n",
    "     **params['train']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Evaluate\"></a>\n",
    "## 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best_weights\n",
    "model_container.load_model_weights(exp_folder)\n",
    "data_gen_test = DataGenerator(\n",
    "    dataset, features, folds=folds_test, batch_size=params_train['batch_size'],\n",
    "    shuffle=False, train=False, scaler=scaler\n",
    ")\n",
    "\n",
    "results = model_container.evaluate(\n",
    "    data_gen_test,\n",
    "    label_list=dataset.label_list,\n",
    "    sequence_time_sec=params_features['sequence_hop_time'],\n",
    "    metric_resolution_sec=1.0)\n",
    "\n",
    "print(results[metrics[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
