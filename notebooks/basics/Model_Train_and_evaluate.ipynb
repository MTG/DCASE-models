{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    " ____   ____    _    ____  _____                          _      _     \n",
    "|  _ \\ / ___|  / \\  / ___|| ____|     _ __ ___   ___   __| | ___| |___ \n",
    "| | | | |     / _ \\ \\___ \\|  _| _____| '_ ` _ \\ / _ \\ / _` |/ _ \\ / __|\n",
    "| |_| | |___ / ___ \\ ___) | |__|_____| | | | | | (_) | (_| |  __/ \\__ \\\n",
    "|____/ \\____/_/   \\_\\____/|_____|    |_| |_| |_|\\___/ \\__,_|\\___|_|___/\n",
    "                                                                        \n",
    "</pre>\n",
    "\n",
    "# DCASE-models Notebooks\n",
    "Python Notebooks for [DCASE-models](https://github.com/pzinemanas/DCASE-models)\n",
    "\n",
    "---\n",
    "### About\n",
    "\n",
    "This notebook shows how to train a model using [DCASE-models](https://github.com/pzinemanas/DCASE-models).\n",
    "\n",
    "### Overview\n",
    "\n",
    "The dataset used is [Urban SED](http://urbansed.weebly.com/), an adaptation of the Convolutional Neural Network (CNN) proposed by Salamon and Bello [[SB-CNN]](http://ieeexplore.ieee.org/document/7829341/) is trained end evaluated.\n",
    "\n",
    "For details on how to download a dataset, extract features or perform data augmentation refer to the respective notebooks.\n",
    "\n",
    "\n",
    "### Organization\n",
    "\n",
    "The Notebook is organized into the following sections.\n",
    "* [1. Prepare data](#Data)\n",
    "* [2. Initialize model](#InitModel)\n",
    "* [3. Train model](#TrainModel)\n",
    "* [4. Evaluate model](#Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "rootdir_path = '../../'\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "sys.path.append(rootdir_path)\n",
    "\n",
    "from dcase_models.data.datasets import URBAN_SED\n",
    "from dcase_models.data.features import MelSpectrogram\n",
    "from dcase_models.model.models import SB_CNN_SED\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.data.data_augmentation import AugmentedDataset\n",
    "from dcase_models.data.scaler import Scaler\n",
    "from dcase_models.util.files import load_json\n",
    "from dcase_models.util.files import mkdir_if_not_exists, save_pickle\n",
    "from dcase_models.util.data import evaluation_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Data\"></a>\n",
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the following steps could be  ommited if *feature_extraction* and *download_and_prepare_datasets* have already been run. Nonetheless, they have been included to make the notebook self contained. For a more detailed explanation refer to the corresponding notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"dataset_path\": \"datasets/URBAN-SED_v2.0.0\",\n",
      "    \"evaluation_mode\": \"train-validate-test\"\n",
      "}\n",
      "{\n",
      "    \"model_arguments\": {},\n",
      "    \"normalizer\": \"minmax\",\n",
      "    \"train_arguments\": {}\n",
      "}\n",
      "{\n",
      "    \"batch_size\": 32,\n",
      "    \"considered_improvement\": 0,\n",
      "    \"early_stopping\": 30,\n",
      "    \"epochs\": 50,\n",
      "    \"learning_rate\": 0.001,\n",
      "    \"optimizer\": \"Adam\",\n",
      "    \"verbose\": 1\n",
      "}\n",
      "URBAN_SED dataset was already downloaded. \n",
      "Features were already extracted for URBAN_SED dataset. \n"
     ]
    }
   ],
   "source": [
    "#load parameters from json file\n",
    "parameters_file = os.path.join(rootdir_path, 'parameters.json')\n",
    "params = load_json(parameters_file)\n",
    "params_dataset = params['datasets']['URBAN_SED']\n",
    "params_features = params['features']\n",
    "params_train = params['train']\n",
    "params_model = params['models']['SB_CNN_SED']\n",
    "\n",
    "#print dataset parmeters\n",
    "print(json.dumps(params_dataset, indent=4, sort_keys=True))\n",
    "# print feature extraction parameters \n",
    "print(json.dumps(params_model, indent=4, sort_keys=True))\n",
    "# print training parameters \n",
    "print(json.dumps(params_train, indent=4, sort_keys=True))\n",
    "\n",
    "features =  MelSpectrogram(sequence_time=params_features['sequence_time'],\n",
    "                           sequence_hop_time=params_features['sequence_hop_time'], \n",
    "                           audio_win=params_features['audio_win'], \n",
    "                           audio_hop=params_features['audio_hop'],  \n",
    "                           sr=params_features['sr'], \n",
    "                           **params_features['MelSpectrogram'])\n",
    "\n",
    "dataset_path = os.path.join(rootdir_path, params_dataset[\"dataset_path\"])\n",
    "dataset = URBAN_SED(dataset_path, sequence_hop_time=params_features['sequence_hop_time'])\n",
    "\n",
    "if dataset.check_if_downloaded():\n",
    "    print('URBAN_SED dataset was already downloaded. ')\n",
    "else:\n",
    "    print('downloading URBAN_SED dataset')\n",
    "    dataset.download()\n",
    "# Extract features\n",
    "if features.check_if_extracted(dataset):\n",
    "    print('Features were already extracted for URBAN_SED dataset. ')\n",
    "else:\n",
    "    print('Extracting features ...')\n",
    "    features.extract(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise data generators and fit scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting scaler ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get train/test folds\n",
    "folds_train, folds_val, folds_test = evaluation_setup('test', dataset.fold_list,\\\n",
    "                                             params_dataset['evaluation_mode'],\n",
    "                                             use_validate_set=True)\n",
    "#initialise train Data Generator\n",
    "data_gen_train = DataGenerator(dataset, features, folds=folds_train,\\\n",
    "                               batch_size=params_train['batch_size'],\n",
    "                               shuffle=True, train=True, scaler=None)\n",
    "# fit scaler\n",
    "scaler = Scaler(normalizer=params_model['normalizer'])\n",
    "print('Fitting scaler ...')\n",
    "scaler.fit(data_gen_train)\n",
    "print('Done!')\n",
    "\n",
    "data_gen_train.set_scaler(scaler)\n",
    "\n",
    "#Initialise validation data Generator\n",
    "\n",
    "data_gen_val = DataGenerator(dataset, features, folds=folds_val,\\\n",
    "                             batch_size=params_train['batch_size'],\n",
    "                             shuffle=False, train=False, scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Model\"></a>\n",
    "## 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                331840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 539,850\n",
      "Trainable params: 539,466\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "features_shape = features.get_shape()\n",
    "n_frames_cnn = features_shape[1]\n",
    "n_freq_cnn = features_shape[2]\n",
    "n_classes = len(dataset.label_list)\n",
    "\n",
    "metrics = ['sed']\n",
    "\n",
    "model_container = SB_CNN_SED(model=None, model_path=None, n_classes=n_classes, \n",
    "                             n_frames_cnn=n_frames_cnn, n_freq_cnn=n_freq_cnn,\n",
    "                             metrics=metrics, **params_model['model_arguments'])\n",
    "\n",
    "model_container.model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Train\"></a>\n",
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 44s 235ms/step - loss: 3.0706\n",
      "F1 = 0.3221, ER = 3.8859 - Best val F1: 0.3221\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 39s 206ms/step - loss: 3.0147\n",
      "F1 = 0.3024, ER = 3.9620 - Best val F1: 0.3221 (0)\n",
      "\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 2.96252s -\n",
      "F1 = 0.3324, ER = 3.0270 - Best val F1: 0.3324\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 39s 205ms/step - loss: 2.9129\n",
      "F1 = 0.3243, ER = 3.3494 - Best val F1: 0.3324 (2)\n",
      "\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 39s 207ms/step - loss: 2.8669\n",
      "F1 = 0.3825, ER = 2.2649 - Best val F1: 0.3825\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 40s 211ms/step - loss: 2.8204\n",
      "F1 = 0.3960, ER = 1.7768 - Best val F1: 0.3960\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 2.7637\n",
      "F1 = 0.4077, ER = 1.3879 - Best val F1: 0.4077\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 39s 210ms/step - loss: 2.7124\n",
      "F1 = 0.4002, ER = 1.3227 - Best val F1: 0.4077 (6)\n",
      "\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 38s 202ms/step - loss: 2.6806\n",
      "F1 = 0.4237, ER = 0.9631 - Best val F1: 0.4237\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 37s 196ms/step - loss: 2.6445\n",
      "F1 = 0.3858, ER = 0.9227 - Best val F1: 0.4237 (8)\n",
      "\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 2.6150\n",
      "F1 = 0.4630, ER = 0.9031 - Best val F1: 0.4630\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 33s 174ms/step - loss: 2.5891\n",
      "F1 = 0.4508, ER = 0.9724 - Best val F1: 0.4630 (10)\n",
      "\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 39s 209ms/step - loss: 2.5571\n",
      "F1 = 0.4413, ER = 0.6919 - Best val F1: 0.4630 (10)\n",
      "\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.5357\n",
      "F1 = 0.5269, ER = 0.6231 - Best val F1: 0.5269\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.5103\n",
      "F1 = 0.4997, ER = 0.7195 - Best val F1: 0.5269 (13)\n",
      "\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 39s 210ms/step - loss: 2.4753\n",
      "F1 = 0.4967, ER = 0.6790 - Best val F1: 0.5269 (13)\n",
      "\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 40s 211ms/step - loss: 2.4512\n",
      "F1 = 0.5381, ER = 0.6071 - Best val F1: 0.5381\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 39s 206ms/step - loss: 2.4303\n",
      "F1 = 0.5446, ER = 0.5946 - Best val F1: 0.5446\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 39s 205ms/step - loss: 2.4200\n",
      "F1 = 0.4761, ER = 0.7986 - Best val F1: 0.5446 (17)\n",
      "\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 37s 199ms/step - loss: 2.3900\n",
      "F1 = 0.4837, ER = 0.8429 - Best val F1: 0.5446 (17)\n",
      "\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 37s 198ms/step - loss: 2.3647\n",
      "F1 = 0.4879, ER = 0.8010 - Best val F1: 0.5446 (17)\n",
      "\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 37s 198ms/step - loss: 2.3595\n",
      "F1 = 0.5671, ER = 0.5821 - Best val F1: 0.5671\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 32s 172ms/step - loss: 2.3373\n",
      "F1 = 0.4604, ER = 0.8527 - Best val F1: 0.5671 (21)\n",
      "\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 39s 210ms/step - loss: 2.3253\n",
      "F1 = 0.5297, ER = 0.6550 - Best val F1: 0.5671 (21)\n",
      "\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 40s 212ms/step - loss: 2.3120\n",
      "F1 = 0.5722, ER = 0.6053 - Best val F1: 0.5722\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 2.2979\n",
      "F1 = 0.5066, ER = 0.7871 - Best val F1: 0.5722 (24)\n",
      "\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.2807\n",
      "F1 = 0.5403, ER = 0.6158 - Best val F1: 0.5722 (24)\n",
      "\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 2.2643\n",
      "F1 = 0.5792, ER = 0.5720 - Best val F1: 0.5792\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 37s 196ms/step - loss: 2.2585\n",
      "F1 = 0.5843, ER = 0.5645 - Best val F1: 0.5843\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 37s 198ms/step - loss: 2.2380\n",
      "F1 = 0.5158, ER = 0.7772 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 31/50\n",
      "188/188 [==============================] - 32s 168ms/step - loss: 2.2272\n",
      "F1 = 0.5649, ER = 0.6184 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.2194\n",
      "F1 = 0.5623, ER = 0.5894 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.2051\n",
      "F1 = 0.5413, ER = 0.6787 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.1979\n",
      "F1 = 0.5621, ER = 0.5877 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 39s 207ms/step - loss: 2.1891\n",
      "F1 = 0.5797, ER = 0.5744 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 39s 209ms/step - loss: 2.1773\n",
      "F1 = 0.5408, ER = 0.6314 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 2.1741\n",
      "F1 = 0.5613, ER = 0.5803 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 37s 196ms/step - loss: 2.1599\n",
      "F1 = 0.5474, ER = 0.6625 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 37s 199ms/step - loss: 2.1517\n",
      "F1 = 0.5331, ER = 0.7678 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 32s 169ms/step - loss: 2.1428\n",
      "F1 = 0.5746, ER = 0.5839 - Best val F1: 0.5843 (28)\n",
      "\n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 39s 210ms/step - loss: 2.1343\n",
      "F1 = 0.5888, ER = 0.5603 - Best val F1: 0.5888\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 42/50\n",
      "188/188 [==============================] - 39s 210ms/step - loss: 2.1239\n",
      "F1 = 0.5731, ER = 0.6356 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 2.1185\n",
      "F1 = 0.5871, ER = 0.5698 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.1126\n",
      "F1 = 0.5678, ER = 0.5826 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 2.1089\n",
      "F1 = 0.5798, ER = 0.5835 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 36s 193ms/step - loss: 2.0956\n",
      "F1 = 0.5880, ER = 0.5648 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 37s 198ms/step - loss: 2.0973\n",
      "F1 = 0.5724, ER = 0.5831 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 32s 173ms/step - loss: 2.0887\n",
      "F1 = 0.5856, ER = 0.5705 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 40s 210ms/step - loss: 2.0789\n",
      "F1 = 0.5832, ER = 0.5795 - Best val F1: 0.5888 (40)\n",
      "\n",
      "Epoch 50/50\n",
      "188/188 [==============================] - 40s 211ms/step - loss: 2.0732\n",
      "F1 = 0.5774, ER = 0.5799 - Best val F1: 0.5888 (40)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp_folder='./output/basics'\n",
    "if not os.path.exists(exp_folder):\n",
    "    os.makedirs(exp_folder)\n",
    "model_container.train(data_gen_train, data_gen_val,\n",
    "                      label_list=dataset.label_list,\n",
    "                      weights_path=exp_folder, **params['train'],\n",
    "                      sequence_time_sec=params_features['sequence_hop_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Evaluate\"></a>\n",
    "## 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment based metrics\n",
      "========================================\n",
      "  Evaluated length                  : 18505.00 sec\n",
      "  Evaluated files                   : 2000 \n",
      "  Segment length                    : 1.00 sec\n",
      "\n",
      "  Overall metrics (micro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 56.27 %\n",
      "    Precision                       : 66.75 %\n",
      "    Recall                          : 48.64 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 0.58 \n",
      "    Substitution rate               : 0.17 \n",
      "    Deletion rate                   : 0.34 \n",
      "    Insertion rate                  : 0.07 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 48.64 %\n",
      "    Specificity                     : 95.97 %\n",
      "    Balanced accuracy               : 72.30 %\n",
      "    Accuracy                        : 89.21 %\n",
      "\n",
      "  Class-wise average metrics (macro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 55.11 %\n",
      "    Precision                       : 69.43 %\n",
      "    Recall                          : 48.61 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 0.75 \n",
      "    Deletion rate                   : 0.51 \n",
      "    Insertion rate                  : 0.24 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 48.61 %\n",
      "    Specificity                     : 95.95 %\n",
      "    Balanced accuracy               : 72.28 %\n",
      "    Accuracy                        : 89.21 %\n",
      "  \n",
      "\n",
      "  Class-wise metrics\n",
      "  ======================================\n",
      "    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n",
      "    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n",
      "    air_condit.. | 2685    1117  | 34.5%    58.7%    24.4%  | 0.93     0.76     0.17   | 24.4%    97.1%    60.8%    86.5%   \n",
      "    car_horn     | 2144    1471  | 66.7%    81.9%    56.2%  | 0.56     0.44     0.12   | 56.2%    98.4%    77.3%    93.5%   \n",
      "    children_p.. | 2870    2510  | 54.9%    58.9%    51.5%  | 0.84     0.49     0.36   | 51.5%    93.4%    72.4%    86.9%   \n",
      "    dog_bark     | 2605    1557  | 56.5%    75.5%    45.1%  | 0.69     0.55     0.15   | 45.1%    97.6%    71.4%    90.2%   \n",
      "    drilling     | 2775    1956  | 55.0%    66.6%    46.9%  | 0.77     0.53     0.24   | 46.9%    95.8%    71.4%    88.5%   \n",
      "    engine_idl.. | 2849    1099  | 42.2%    75.9%    29.3%  | 0.80     0.71     0.09   | 29.3%    98.3%    63.8%    87.7%   \n",
      "    gun_shot     | 2264    912   | 49.4%    86.1%    34.7%  | 0.71     0.65     0.06   | 34.7%    99.2%    66.9%    91.3%   \n",
      "    jackhammer   | 2674    3779  | 68.1%    58.1%    82.2%  | 0.77     0.18     0.59   | 82.2%    90.0%    86.1%    88.9%   \n",
      "    siren        | 2800    2453  | 65.0%    69.5%    60.9%  | 0.66     0.39     0.27   | 60.9%    95.2%    78.1%    90.1%   \n",
      "    street_music | 2742    2387  | 58.7%    63.0%    54.9%  | 0.77     0.45     0.32   | 54.9%    94.4%    74.6%    88.5%   \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best_weights\n",
    "model_container.load_model_weights(exp_folder)\n",
    "data_gen_test = DataGenerator(dataset, features, folds=folds_test,\\\n",
    "                              batch_size=params_train['batch_size'],\\\n",
    "                              shuffle=False, train=False, scaler=scaler)\n",
    "\n",
    "kwargs = {'sequence_time_sec': params_features['sequence_hop_time'],\n",
    "          'metric_resolution_sec': 1.0}\n",
    "results = model_container.evaluate(data_gen_test, label_list=dataset.label_list, **kwargs)\n",
    "\n",
    "print(results[metrics[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
