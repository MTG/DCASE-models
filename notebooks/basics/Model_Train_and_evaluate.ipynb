{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    " ____   ____    _    ____  _____                          _      _     \n",
    "|  _ \\ / ___|  / \\  / ___|| ____|     _ __ ___   ___   __| | ___| |___ \n",
    "| | | | |     / _ \\ \\___ \\|  _| _____| '_ ` _ \\ / _ \\ / _` |/ _ \\ / __|\n",
    "| |_| | |___ / ___ \\ ___) | |__|_____| | | | | | (_) | (_| |  __/ \\__ \\\n",
    "|____/ \\____/_/   \\_\\____/|_____|    |_| |_| |_|\\___/ \\__,_|\\___|_|___/\n",
    "                                                                        \n",
    "</pre>\n",
    "\n",
    "# DCASE-models Notebooks\n",
    "Python Notebooks for [DCASE-models](https://github.com/pzinemanas/DCASE-models)\n",
    "\n",
    "---\n",
    "### About\n",
    "\n",
    "This notebook shows how to train a model using [DCASE-models](https://github.com/pzinemanas/DCASE-models).\n",
    "\n",
    "### Overview\n",
    "\n",
    "The dataset used is [Urban SED](http://urbansed.weebly.com/), an adaptation of the Convolutional Neural Network (CNN) proposed by Salamon and Bello [[SB-CNN]](http://ieeexplore.ieee.org/document/7829341/) is trained end evaluated.\n",
    "\n",
    "For details on how to download a dataset, extract features or perform data augmentation refer to the respective notebooks.\n",
    "\n",
    "\n",
    "### Organization\n",
    "\n",
    "The Notebook is organized into the following sections.\n",
    "* [1. Prepare data](#Data)\n",
    "* [2. Initialize model](#InitModel)\n",
    "* [3. Train model](#TrainModel)\n",
    "* [4. Evaluate model](#Evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/clusteruy/home/ihounie/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "rootdir_path = '../../'\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import warnings\n",
    "sys.path.append(rootdir_path)\n",
    "\n",
    "from dcase_models.data.datasets import URBAN_SED\n",
    "from dcase_models.data.features import MelSpectrogram\n",
    "from dcase_models.model.models import SB_CNN_SED\n",
    "from dcase_models.data.data_generator import DataGenerator\n",
    "from dcase_models.data.data_augmentation import AugmentedDataset\n",
    "from dcase_models.data.scaler import Scaler\n",
    "from dcase_models.util.files import load_json\n",
    "from dcase_models.util.files import mkdir_if_not_exists, save_pickle\n",
    "from dcase_models.util.data import evaluation_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Data\"></a>\n",
    "## 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the following steps could be  ommited if *feature_extraction* and *download_and_prepare_datasets* have already been run. Nonetheless, they have been included to make the notebook self contained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"MelSpectrogram\": {\n",
      "        \"mel_bands\": 64,\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"Openl3\": {\n",
      "        \"content_type\": \"env\",\n",
      "        \"embedding_size\": 512,\n",
      "        \"input_repr\": \"mel256\"\n",
      "    },\n",
      "    \"Spectrogram\": {\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"audio_hop\": 690,\n",
      "    \"audio_win\": 1024,\n",
      "    \"sequence_hop_time\": 1.0,\n",
      "    \"sequence_time\": 2.0,\n",
      "    \"sr\": 22050\n",
      "}\n",
      "{\n",
      "    \"MelSpectrogram\": {\n",
      "        \"mel_bands\": 64,\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"Openl3\": {\n",
      "        \"content_type\": \"env\",\n",
      "        \"embedding_size\": 512,\n",
      "        \"input_repr\": \"mel256\"\n",
      "    },\n",
      "    \"Spectrogram\": {\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"audio_hop\": 690,\n",
      "    \"audio_win\": 1024,\n",
      "    \"sequence_hop_time\": 1.0,\n",
      "    \"sequence_time\": 2.0,\n",
      "    \"sr\": 22050\n",
      "}\n",
      "{\n",
      "    \"MelSpectrogram\": {\n",
      "        \"mel_bands\": 64,\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"Openl3\": {\n",
      "        \"content_type\": \"env\",\n",
      "        \"embedding_size\": 512,\n",
      "        \"input_repr\": \"mel256\"\n",
      "    },\n",
      "    \"Spectrogram\": {\n",
      "        \"n_fft\": 1024\n",
      "    },\n",
      "    \"audio_hop\": 690,\n",
      "    \"audio_win\": 1024,\n",
      "    \"sequence_hop_time\": 1.0,\n",
      "    \"sequence_time\": 2.0,\n",
      "    \"sr\": 22050\n",
      "}\n",
      "URBAN_SED dataset was already downloaded. \n",
      "Features were already extracted for URBAN_SED dataset. \n"
     ]
    }
   ],
   "source": [
    "#load parameters from json file\n",
    "parameters_file = os.path.join(rootdir_path, 'parameters.json')\n",
    "params = load_json(parameters_file)\n",
    "params_dataset = params['datasets']['URBAN_SED']\n",
    "params_features = params['features']\n",
    "params_train = params['train']\n",
    "params_model = params['models']['SB_CNN_SED']\n",
    "kwargs = {'sequence_hop_time': params_features['sequence_hop_time']}\n",
    "#print dataset parmeters\n",
    "print(json.dumps(params_features, indent=4, sort_keys=True))\n",
    "# print feature extraction parameters \n",
    "print(json.dumps(params_features, indent=4, sort_keys=True))\n",
    "# print training parameters \n",
    "print(json.dumps(params_features, indent=4, sort_keys=True))\n",
    "\n",
    "features =  MelSpectrogram(sequence_time=params_features['sequence_time'], \\\n",
    "                                            sequence_hop_time=params_features['sequence_hop_time'], \n",
    "                                            audio_win=params_features['audio_win'], \n",
    "                                            audio_hop=params_features['audio_hop'],  \n",
    "                                            sr=params_features['sr'], \n",
    "                                            **params_features['MelSpectrogram'])\n",
    "dataset = URBAN_SED(os.path.join(rootdir_path, params_dataset[\"dataset_path\"]))\n",
    "\n",
    "if dataset.check_if_downloaded():\n",
    "    print('URBAN_SED dataset was already downloaded. ')\n",
    "else:\n",
    "    print('downloading URBAN_SED dataset')\n",
    "    dataset.download()\n",
    "# Extract features\n",
    "if features.check_if_extracted(dataset):\n",
    "    print('Features were already extracted for URBAN_SED dataset. ')\n",
    "else:\n",
    "    print('Extracting features ...')\n",
    "    features.extract(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise data generators and fit scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting features ...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Get train/test folds\n",
    "folds_train, folds_val, folds_test = evaluation_setup('test', dataset.fold_list,\\\n",
    "                                             params_dataset['evaluation_mode'],\n",
    "                                             use_validate_set=True)\n",
    "#initialise train Data Generator\n",
    "data_gen_train = DataGenerator(dataset, features, folds=folds_train,\\\n",
    "                                batch_size=params_train['batch_size'],\n",
    "                                shuffle=True, train=True, scaler=None)\n",
    "# fit scaler\n",
    "scaler = Scaler(normalizer=params_model['normalizer'])\n",
    "print('Fitting features ...')\n",
    "scaler.fit(data_gen_train)\n",
    "print('Done!')\n",
    "\n",
    "data_gen_train.set_scaler(scaler)\n",
    "\n",
    "#Initialise validation data Generator\n",
    "\n",
    "data_gen_val = DataGenerator(dataset, features, folds=folds_val,\\\n",
    "                             batch_size=params_train['batch_size'],\n",
    "                             shuffle=False, train=False, scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Model\"></a>\n",
    "## 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64, 64)            0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 64, 64, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        102464    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 13, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 9, 9, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5184)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                331840    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 539,850\n",
      "Trainable params: 539,466\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "params_model = params['models']['SB_CNN_SED']\n",
    "metrics = ['sed']\n",
    "X, y = data_gen_train.get_data_batch(0)\n",
    " \n",
    "n_frames_cnn = X.shape[1]\n",
    "n_freq_cnn = X.shape[2]\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "metrics = ['sed']\n",
    "\n",
    "model_container = SB_CNN_SED(model=None, model_path=None, n_classes=n_classes, \n",
    "                             n_frames_cnn=n_frames_cnn, n_freq_cnn=n_freq_cnn,\n",
    "                             metrics=metrics, **params_model['model_arguments'])\n",
    "\n",
    "model_container.model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Train\"></a>\n",
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 33s 178ms/step - loss: 1.8467\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713\n",
      "                  (IMPROVEMENT, saving)\n",
      "\n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 39s 209ms/step - loss: 1.8473\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 39s 208ms/step - loss: 1.8454\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 39s 208ms/step - loss: 1.8465\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 39s 208ms/step - loss: 1.8468\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 39s 208ms/step - loss: 1.8445\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 39s 207ms/step - loss: 1.8462\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 39s 209ms/step - loss: 1.8458\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 39s 208ms/step - loss: 1.8460\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 39s 208ms/step - loss: 1.8457\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 39s 207ms/step - loss: 1.8466\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 1.8464\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.8447\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.8478\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.8464\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 37s 199ms/step - loss: 1.8457\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 37s 198ms/step - loss: 1.8463\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.8454\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 37s 198ms/step - loss: 1.8445\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 37s 198ms/step - loss: 1.8449\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.8457\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.8458\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 38s 199ms/step - loss: 1.8451\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.8449\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 38s 201ms/step - loss: 1.8460\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 38s 200ms/step - loss: 1.8432\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 38s 203ms/step - loss: 1.8437\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 38s 204ms/step - loss: 1.8457\n",
      "F1 = 0.1713, ER = 9.6769 - Best val F1: 0.1713 (0)\n",
      "\n",
      "Epoch 29/50\n",
      " 59/188 [========>.....................] - ETA: 23s - loss: 1.8506"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-76920c693506>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mlabel_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                       \u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                       sequence_time_sec=params_features['sequence_hop_time'])\n\u001b[0m",
      "\u001b[0;32m~/DCASE-models/dcase_models/model/container.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_train, data_val, weights_path, optimizer, learning_rate, early_stopping, considered_improvement, losses, loss_weights, sequence_time_sec, metric_resolution_sec, label_list, shuffle, **kwargs_keras_fit)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetrics_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mkwargs_keras_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m                 \u001b[0;31m# use_multiprocessing=True,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;31m# workers=6)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp_folder='./output/basics'\n",
    "if not os.path.exists(exp_folder):\n",
    "    os.makedirs(exp_folder)\n",
    "model_container.train(data_gen_train, data_gen_val,\\\n",
    "                      label_list=dataset.label_list,\n",
    "                      weights_path=exp_folder, **params['train'],\n",
    "                      sequence_time_sec=params_features['sequence_hop_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Evaluate\"></a>\n",
    "## 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment based metrics\n",
      "========================================\n",
      "  Evaluated length                  : 20000.00 sec\n",
      "  Evaluated files                   : 2000 \n",
      "  Segment length                    : 1.00 sec\n",
      "\n",
      "  Overall metrics (micro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 14.70 %\n",
      "    Precision                       : 7.93 %\n",
      "    Recall                          : 99.77 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 11.58 \n",
      "    Substitution rate               : 0.00 \n",
      "    Deletion rate                   : 0.00 \n",
      "    Insertion rate                  : 11.58 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 99.77 %\n",
      "    Specificity                     : 0.32 %\n",
      "    Balanced accuracy               : 50.05 %\n",
      "    Accuracy                        : 8.20 %\n",
      "\n",
      "  Class-wise average metrics (macro-average)\n",
      "  ======================================\n",
      "  F-measure\n",
      "    F-measure (F1)                  : 14.69 %\n",
      "    Precision                       : 7.93 %\n",
      "    Recall                          : 99.77 %\n",
      "  Error rate\n",
      "    Error rate (ER)                 : 11.65 \n",
      "    Deletion rate                   : 0.00 \n",
      "    Insertion rate                  : 11.65 \n",
      "  Accuracy\n",
      "    Sensitivity                     : 99.77 %\n",
      "    Specificity                     : 0.32 %\n",
      "    Balanced accuracy               : 50.05 %\n",
      "    Accuracy                        : 8.20 %\n",
      "  \n",
      "\n",
      "  Class-wise metrics\n",
      "  ======================================\n",
      "    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    | Sens     Spec     Bacc     Acc     \n",
      "    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ | ------   ------   ------   ------  \n",
      "    air_condit.. | 1701    20000 | 15.7%    8.5%     100.0% | 10.76    0.00     10.76  | 100.0%   0.0%     50.0%    8.5%    \n",
      "    car_horn     | 1343    20000 | 12.6%    6.7%     100.0% | 13.89    0.00     13.89  | 100.0%   0.0%     50.0%    6.7%    \n",
      "    children_p.. | 1708    19936 | 15.8%    8.6%     99.9%  | 10.67    0.00     10.67  | 99.9%    0.3%     50.1%    8.8%    \n",
      "    dog_bark     | 1524    19997 | 14.2%    7.6%     100.0% | 12.12    0.00     12.12  | 100.0%   0.0%     50.0%    7.6%    \n",
      "    drilling     | 1728    20000 | 15.9%    8.6%     100.0% | 10.57    0.00     10.57  | 100.0%   0.0%     50.0%    8.6%    \n",
      "    engine_idl.. | 1574    19997 | 14.6%    7.9%     100.0% | 11.70    0.00     11.70  | 100.0%   0.0%     50.0%    7.9%    \n",
      "    gun_shot     | 1467    19998 | 13.7%    7.3%     100.0% | 12.63    0.00     12.63  | 100.0%   0.0%     50.0%    7.3%    \n",
      "    jackhammer   | 1568    19467 | 14.6%    7.9%     97.8%  | 11.46    0.02     11.44  | 97.8%    2.7%     50.2%    10.2%   \n",
      "    siren        | 1638    19977 | 15.2%    8.2%     100.0% | 11.20    0.00     11.20  | 100.0%   0.1%     50.1%    8.3%    \n",
      "    street_music | 1601    20000 | 14.8%    8.0%     100.0% | 11.49    0.00     11.49  | 100.0%   0.0%     50.0%    8.0%    \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load best_weights\n",
    "model_container.load_model_weights(exp_folder)\n",
    "data_gen_test = DataGenerator(dataset, features, folds=folds_test,\\\n",
    "                              batch_size=params_train['batch_size'],\\\n",
    "                              shuffle=False, train=False, scaler=scaler)\n",
    "\n",
    "kwargs = {'sequence_time_sec': params_features['sequence_hop_time'],\n",
    "          'metric_resolution_sec': 1.0}\n",
    "results = model_container.evaluate(data_gen_test, label_list=dataset.label_list, **kwargs)\n",
    "\n",
    "print(results[metrics[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
